# -*- coding: utf-8 -*-
"""ChikaAmanna_SportsPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UYp8ioQLuqr_C6HNNtY4JYTFo5fwLVXl
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive')

df_FIFA = pd.read_csv('/content/drive/MyDrive/FIFA dataset/male_players (legacy).csv', na_values = '-', low_memory=False)
df_player22 = pd.read_csv('/content/drive/MyDrive/FIFA dataset/players_22-1.csv', na_values = '-', low_memory=False)
df_FIFA.shape

df_FIFA

def DropColumns(df_FIFA):
  LessMissing =[]
  MoreMissing = []
  for i in df_FIFA.columns:
    if "url" in i:
        MoreMissing.append(i)
        # use 0.3 for the 30%
    if((df_FIFA[i].isnull().sum())<(0.3*(df_FIFA.shape[0]))):
      LessMissing.append(i)
    else:
      MoreMissing.append(i)
  # df_FIFA = df_FIFA[LessMissing]
  df_FIFA.drop(MoreMissing, axis = 1, inplace = True)
  return df_FIFA

def RemoveNANs(df_FIFA2):
  df_FIFA2 = DropColumns(df_FIFA2)
  # Separating features into numeric and categorical variable
  numeric_data = df_FIFA2.select_dtypes(include = np.number)
  non_numeric_data = df_FIFA2.select_dtypes(include = ['object'])
  label_encoders = {}
  # handling missing values in the non numeric data
  for column in non_numeric_data.columns:
    le = LabelEncoder()
    non_numeric_data[column] = le.fit_transform(non_numeric_data[column].astype(str))
    label_encoders[column] = le
    # handling missing values in the non numeric data
  imp = IterativeImputer(max_iter = 10, random_state = 0)
  numeric_data = pd.DataFrame(np.round(imp.fit_transform(numeric_data)), columns = numeric_data.columns)
  Y = numeric_data['overall'].astype(int)
  X = pd.concat([numeric_data, non_numeric_data], axis=1)
  # Check for classes with only one sample
  value_counts = Y.value_counts()
  single_sample_classes = value_counts[value_counts == 1].index.tolist()

  # Remove rows with target values belonging to single-sample classes
  X = X[~Y.isin(single_sample_classes)]
  Y = Y[~Y.isin(single_sample_classes)]
  correlations = X.corr()['overall'].sort_values(ascending=False)
  strong_correlations = correlations[:7]
  strong_correlations_columns  = strong_correlations.index.tolist()
  strong_correlations_columns
  strong_correlations_columns.remove('overall')
  X = X[strong_correlations_columns]
  scaler = StandardScaler()
  X = scaler.fit_transform(X)

  return X, Y

print(X.shape)

# Calculate the correlation between each variable and player's overall rating
correlations[0:7]

X, Y = RemoveNANs(df_player22)
Y

X.shape

Xtrain, Xtest, Ytrain,Ytest = train_test_split(X, Y,test_size = 0.2, random_state=42, stratify=Y)
Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape

"""# Base Training Phase

## 1] Ridge Model
"""

from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

#Train the model
model = Ridge() # you replace put ElasticNet or lasso on the Ridge function to compare and  train
model.fit(Xtrain, Ytrain)

#Test the model
y_pred = model.predict(Xtest)

print(f""" Mean Absolute Error = {mean_absolute_error(y_pred, Ytest)},
           Mean Squared Error = {mean_squared_error(y_pred, Ytest)},
           Root Mean Squared Error = {np.sqrt(mean_squared_error(y_pred, Ytest))},
           r2 score = {r2_score(y_pred, Ytest)}
           """)

"""## 2] ElasticNet Model"""

from sklearn.linear_model import ElasticNet
#Train the model
model = ElasticNet() # you replace put ElasticNet or lasso on the Ridge function to compare and  train
model.fit(Xtrain, Ytrain)

#Test the model
y_pred = model.predict(Xtest)

print(f""" Mean Absolute Error = {mean_absolute_error(y_pred, Ytest)},
           Mean Squared Error = {mean_squared_error(y_pred, Ytest)},
           Root Mean Squared Error = {np.sqrt(mean_squared_error(y_pred, Ytest))},
           r2 score = {r2_score(y_pred, Ytest)}
           """)

"""## 3] Lasso Model"""

from sklearn.linear_model import Lasso
#Train the model
model = Lasso() # you replace put ElasticNet or lasso on the Ridge function to compare and  train
model.fit(Xtrain, Ytrain)

#Test the model
y_pred = model.predict(Xtest)

print(f""" Mean Absolute Error = {mean_absolute_error(y_pred, Ytest)},
           Mean Squared Error = {mean_squared_error(y_pred, Ytest)},
           Root Mean Squared Error = {np.sqrt(mean_squared_error(y_pred, Ytest))},
           r2 score = {r2_score(y_pred, Ytest)}
           """)

"""## 4] Linear Regression Model"""

from sklearn.linear_model import LinearRegression

# Train and evaluate linear regression model
linear_model = LinearRegression()
linear_model.fit(Xtrain, Ytrain)
y_pred_linear = linear_model.predict(Xtest)
print(f""" Mean Absolute Error = {mean_absolute_error(y_pred_linear, Ytest)},
           Mean Squared Error = {mean_squared_error(y_pred_linear, Ytest)},
           Root Mean Squared Error = {np.sqrt(mean_squared_error(y_pred_linear, Ytest))},
           r2 score = {r2_score(y_pred_linear, Ytest)}
           """)

"""## 5] Decision Tree Regressor Model"""

from sklearn.tree import DecisionTreeRegressor

# Train and evaluate  Decision Tree Regressor model
dtree = DecisionTreeRegressor(max_depth = 12) #Change it to 7 and 12 and compare the values
dtree.fit(Xtrain, Ytrain)
y_pred = dtree.predict(Xtest)
print(f""" Mean Absolute Error = {mean_absolute_error(y_pred, Ytest)},
           Mean Squared Error = {mean_squared_error(y_pred, Ytest)},
           Root Mean Squared Error = {np.sqrt(mean_squared_error(y_pred, Ytest))},
           r2 score = {r2_score(y_pred, Ytest)}
           """)

"""# Training and Evaluating Ensemble Models"""

from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score
from xgboost import XGBRegressor

rf_model = RandomForestRegressor(random_state=42)
# Define parameter grids for RandomForestRegressor model
rf_param_grid = {
    'n_estimators': [500, 600],
    'max_depth': [2, 10, 20],
    'min_samples_split': [2, 5]
}
# Perform grid search with cross-validation
rf_grid_search = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=5, scoring='neg_mean_squared_error')
rf_grid_search.fit(Xtrain, Ytrain)
rf_r2 = r2_score(Ytest, rf_grid_search.predict(Xtest))
rf_best_model = rf_grid_search.best_estimator_
rf_best_model.fit(Xtrain, Ytrain)
rf_y_pred = rf_best_model.predict(Xtest)
rf_mse = mean_squared_error(Ytest, rf_y_pred)
cross_val_score(rf_best_model, Xtrain, Ytrain, cv=5, scoring='neg_mean_squared_error')

print("Random Forest MSE:", rf_mse)
print("Random Forest R2:", rf_r2)
print("Random Forest best parameters:", rf_grid_search.best_params_)
print("Random Forest best score:", rf_grid_search.best_score_)
print("Random Forest best estimator:", rf_grid_search.best_estimator_)
print("Random Forest feature importances:", rf_grid_search.best_estimator_.feature_importances_)

xgb_model = XGBRegressor(random_state=42)
xgb_param_grid = {
    'n_estimators': [600, 650],
    'max_depth': [3, 6, 10],
    'learning_rate': [0.01, 0.1, 0.2]
}

xgb_grid = GridSearchCV(xgb_model, xgb_param_grid, cv=5, scoring='neg_mean_squared_error')
xgb_grid.fit(Xtrain, Ytrain)
xgb_grid_search = xgb_grid.best_estimator_
xgb_grid_search.fit(Xtrain, Ytrain)
xgb_y_pred = xgb_grid_search.predict(Xtest)
xgb_mse = mean_squared_error(Ytest, xgb_y_pred)
xgb_cross_val = cross_val_score(xgb_grid_search, Xtrain, Ytrain, cv=5, scoring='neg_mean_squared_error')
xgb_r2 = r2_score(Ytest, xgb_y_pred)

print("XGBoost MSE:", xgb_mse)
print("XGBoost R2:", xgb_r2)
print("XGBoost best score:", xgb_grid.best_score_)
print("XGBoost best estimator:", xgb_grid.best_estimator_)
print("XGBoost feature importances:", xgb_grid.best_estimator_.feature_importances_)
print("XGBoost cross validation score:", xgb_cross_val)

gb_model = GradientBoostingRegressor(random_state=42)
gb_param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [3, 5, 10],
    'learning_rate': [0.01, 0.1, 0.2]
}
gb_grid = GridSearchCV(gb_model, gb_param_grid, cv=5, scoring='neg_mean_squared_error')
# gb_grid_search = GridSearchCV(estimator=gb_model, param_grid=gb_param_grid, cv=5, scoring='neg_mean_squared_error')
gb_grid.fit(Xtrain, Ytrain)
gb_grid_search = gb_grid.best_estimator_
gb_grid_search.fit(Xtrain, Ytrain)
gb_y_pred = gb_grid_search.predict(Xtest)
gb_mse = mean_squared_error(Ytest, gb_y_pred)
gb_cross_val = cross_val_score(gb_grid_search, Xtrain, Ytrain, cv=5, scoring='neg_mean_squared_error')
gb_r2 = r2_score(Ytest, gb_y_pred)


print("Gradient Boosting MSE:", gb_mse)
print("Gradient Boosting R2:", gb_r2)
print("Gradient Boosting cross validation score:", gb_cross_val)
#print("Gradient Boosting feature importances:", gb_grid_search.feature_importances_)
print("Gradient Boosting feature importances:", gb_grid_search.feature_importances_) # Changed line
print("Gradient Boosting best parameters:", gb_grid.best_params_)
print("Gradient Boosting best score:", gb_grid.best_score_)
print("Gradient Boosting best estimator:", gb_grid.best_estimator_)

adb_model = AdaBoostRegressor(random_state=42)
adb_param_grid = {
    'n_estimators': [700, 800],
    'learning_rate': [0.01, 0.1, 0.2]
}
adb_grid_search = GridSearchCV(estimator=adb_model, param_grid=adb_param_grid, cv=5, scoring='neg_mean_squared_error')
adb_grid_search.fit(Xtrain, Ytrain)
adb_best_model = adb_grid_search.best_estimator_
adb_best_model.fit(Xtrain, Ytrain)
adb_y_pred = adb_best_model.predict(Xtest)
adb_mse = mean_squared_error(Ytest, adb_y_pred)
adb_cross_val = cross_val_score(adb_best_model, Xtrain, Ytrain, cv=5, scoring='neg_mean_squared_error')
adb_r2 = r2_score(Ytest, adb_y_pred)
# adb_best_params = adb_grid_search.best_params_
# adb_best_score = adb_grid_search.best_score_
# adb_best_estimator = adb_grid_search.best_estimator_

print("AdaBoosting Best Model:", adb_best_model)
print("AdaBoosting MSE:", adb_mse)
print("AdaBoosting R2:", adb_r2)
print("AdaBoosting cross validation score:", adb_cross_val)
# print("AdaBoosting feature importances:", adb_grid_search.feature_importances_)
print("AdaBoosting feature importances:", adb_best_model.feature_importances_)
print("Gradient Boosting best parameters:", adb_grid_search.best_params_)
print("AdaBoosting best model feature importances:", adb_best_model.feature_importances_)

import joblib
import pickle as pkl

# Assuming `gb_grid_search` is your trained model
final_model = gb_grid_search

# Save the trained model using joblib
joblib.dump(final_model, '/content/drive/MyDrive/Colab Notebooks/gb_grid_search_joblib.pkl')